{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация - предсказание на основе размеченных данных.\n",
    "\n",
    "В кластеризации у нас были данные $X$ размерности $(m, n)$, $m$ - количество объектов, которые мы стараемся разделить на K осмысленных групп.\n",
    "\n",
    "В классификации, у нас есть данные $X$ размерности $(m, n)$ и $Y (m, 1)$, где $Y$ - это так называемая целевая переменная. Каждому объекту из $X$ сопоставлена метка/значение из $Y$. Задача - для новых данных $X^*$ предсказать правильные значения $Y^*$. Другими словами, нужно выучить некоторую функцию $$f(X)=Y$$ которая может затем использоваться для любых других входных данных.\n",
    "\n",
    "В качестве Y могут использоваться как метки классов (собственно задача классификации), так и некоторые значения (задача регрессии)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/9/97/Classifier.svg)\n",
    "\n",
    "**Классификация** - попытка предсказать класс объекта на основе существующих данных.\n",
    "\n",
    "Примеры: \n",
    "- пойдёт завтра дождь или нет\n",
    "- есть ли на изображении объект\n",
    "- будет выдан кредит или нет\n",
    "- болен человек или нет\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классификации по умолчанию переменная $Y$ - категориальная, состоящая из нескольких классов. Для классических алгоритмов, мы по умолчанию считаем, что $|Y|=2$, причем классы обозначены $\\{0, 1\\}$ или $\\{-1, 1\\}$ (в некоторых алгоритмах важны данные значения, в некоторых классы можно называть хоть строчками.\n",
    "\n",
    "Для решения задачи классификации придуманы различные алгоритмы: логистическая регрессия, KNN (алгоритм ближайших соседей), Деревья решений (Случайный лес и др.), Бустинг, SVM (Машина опорных векторов), нейроночки.\n",
    "\n",
    "Каждый из алгоритмов строит свою математическую модель или решает задачу своим способом. Важными показателями для алгоритмов являются скорость работы, область практического использования и интерпретируемость модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деревья решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деревья решений - алгоритм, создающий одновременно модель классификации данных и удобную структуру представления этой же модели. \n",
    "\n",
    "Словарь: корень (корневой узел), родитель/предок, потомок, лист.\n",
    "\n",
    "Под деревом понимается бинарная структура, которая на каждой глубине разделяется на 2 поддерева. Данное разделение всегда происходит по одному из признаков, по некоторому \"разделочному\" значению. Разделение происходит по информационному признаку: чем больше информации даёт разделение - тем лучше. Построение дерева происходит по обучающей выборке (для которой известны метки); построение завершается когда в каждом \"листе\" дерева (конечном узле) остались только объекты одного класса. Объекты по сути перемещаются от корня дерева к какому-нибудь листу следуя указаниям промежуточных узлов. При тестовом использовании модели, новый объект таким же образом перемещается от корня к какому-нибудь листу: попадая в лист, объекту присваивается класс этого листа, то есть класс объектов из этого листа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример - что такое информация?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://hsto.org/storage2/173/96f/27f/17396f27f81e9bb312f2f01aa1254dbe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для математического подсчёта информации используются либо энтропия, либо критерий Джинни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества модели <a name=\"metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче классификации в качестве метрик качества, как правило, используют метрики связанные с так называемой матрицей смежности. \n",
    "Метрики в питоне можно посмотреть [здесь](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](confusion.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$TP$, True Positive - Число правильно угаданных объектов положительного класса\n",
    "\n",
    "$TN$, True Negative - Число правильно угаданных объектов отрицательного/негативного/нулевого класса\n",
    "\n",
    "$FP$, False Positive - Число объектов класса 0, определённых к классу 1, ошибка 1-го рода\n",
    "\n",
    "$FN$, False Negative - Число объектов класса 1, определённых к классу 0, ошибка 2-го рода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$N = TP+TN+FP+FN$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy = \\frac{TP+TN}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Recall = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Precision=\\frac{TP}{TP+FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F1-score=\\frac{2*Recall*Precision}{Recall+Precision}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а также, $Specificity, Sensitivity, ROC AUC$ и другие..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6274165202108963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  212\n",
       "1  0  357"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.ones(y.shape)\n",
    "print(\"Accuracy: \", accuracy_score(y, y_pred))\n",
    "pd.DataFrame(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  212    0\n",
       "1    0  357"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X, y)\n",
    "y_pred = dt.predict(X)\n",
    "pd.DataFrame(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       142\n",
      "           1       0.94      0.91      0.93       257\n",
      "\n",
      "    accuracy                           0.91       399\n",
      "   macro avg       0.90      0.91      0.90       399\n",
      "weighted avg       0.91      0.91      0.91       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введём понятие вероятность положительного предсказания $p(x)$. Под этим понятием мы будем понимать оценку вероятности того, что объект принадлежит положительному классу. \n",
    "\n",
    "$ROC AUC$ (Receiver Operating Characteristic Area Under Curve) - комплексная метрика оценки качества бинарной классификации. С одной стороны это самая сложная метрика, использующая не предсказанные классы, а вероятности положительного предсказания $p(x)$, все возможные уровни значимости и confusion matrix. \n",
    "\n",
    "Порядок построения ROC-кривой следующий:\n",
    "- Для каждого значения $\\alpha$ оцениваются $FPR$ и $TPR$ - False Positive Rate и True Positive Rate:\n",
    "$$TPR = Recall = \\frac{TP}{TP+FN}$$\n",
    "$$FPR = \\frac{FP}{FP+TN}$$\n",
    "- Значение $\\alpha$ выбирается от 0 до 1. Значения $TP$, $FP$, $FN$ и $TN$ подсчитываются из вероятностей: модель предсказывает класс 0, если $p(x) < \\alpha$, иначе класс 1.\n",
    "- $FPR$ и $TPR$ откладываются на осях X, Y соответственно. Для всех $\\alpha$ строятся точки, которые последовательно соединяются. Полученная кривая - это $ROC$. Площадь под кривой - $ROC AUC$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что это всё даёт нам на практике? Во-первых, $FPR$ и $TPR$ совместно позволяют нам отслеживать баланс классов. Так, если предположить, что оба класса сбалансированы и $FPR > TPR$, точность будет меньше 50%, что является неудовлетворительным результатом. Поэтому, будем считать, что $FPR < TPR$ для хорошей модели.\n",
    "\n",
    "Во-вторых, изменение $\\alpha$ позволяет нам контролировать ошибки 1го и 2го рода. Как мы помним, для некоторых приложений особо важно не допускать ошибок 2го рода, пусть взамен мы получаем большое количество ложно-положительных результатов. Значит, изменяя $\\alpha$, мы проверяем классификатор во всех режимах работы.\n",
    "\n",
    "Наконец, чем сильнее разница между $TPR$ и $FPR$, тем выше расположены точки на графике, тем больше площадь под кривой. Таким образом, $ROC AUC$ тем больше, чем лучше предсказательная способность модели при любом уровне значимости. \n",
    "\n",
    "Покажем на примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>p(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  p(x)\n",
       "0      0  0.05\n",
       "1      0  0.10\n",
       "2      0  0.15\n",
       "3      0  0.30\n",
       "4      1  0.45\n",
       "5      1  0.50\n",
       "6      1  0.50\n",
       "7      1  0.70\n",
       "8      1  0.90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = [0, 0, 1, 0, 1, 1, 0, 1, 1]\n",
    "#objects = [0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "#objects = [0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "p_x = [0.05, 0.1, 0.15, 0.3, 0.45, 0.5, 0.5, 0.7, 0.9]\n",
    "example = pd.DataFrame()\n",
    "example['class'] = objects\n",
    "example['p(x)'] = p_x\n",
    "display(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_alpha(i, example):\n",
    "    previous_alpha = -0.01\n",
    "    next_alpha = 1.01\n",
    "    if i != 0:\n",
    "        previous_alpha = example['p(x)'][i-1]\n",
    "    if i != example.shape[0]:\n",
    "        next_alpha = example['p(x)'][i]\n",
    "    if previous_alpha == next_alpha:\n",
    "        return 'equal'\n",
    "    return (previous_alpha + next_alpha) / 2\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(example.shape[0] + 1):\n",
    "    alpha = calculate_alpha(i, example)\n",
    "    if alpha == 'equal':\n",
    "        continue\n",
    "    TP = example[example['p(x)'] > alpha]['class'].sum()\n",
    "    FP = (1 - example[example['p(x)'] > alpha]['class']).sum()\n",
    "    TN = (1 - example[example['p(x)'] < alpha]['class']).sum()\n",
    "    FN = example[example['p(x)'] < alpha]['class'].sum()\n",
    "    print(\"Alpha:\", alpha)\n",
    "    print(\"TP:\", TP, \" FN:\", FN, \" FP:\", FP, \" TN:\", TN)\n",
    "    TPR = TP / (TP+FN)\n",
    "    FPR = FP / (FP+TN)\n",
    "    print(\"FPR:\", FPR, \" TPR:\", TPR)\n",
    "    print()\n",
    "    x.append(FPR)\n",
    "    y.append(TPR)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.plot([0, 0, 1, 1, 0], [0, 1, 1, 0, 0], '-k')\n",
    "    plt.plot([0, 1], [0, 1], '--g')\n",
    "    plt.plot(x, y, '*-r')\n",
    "    plt.show()\n",
    "    input()\n",
    "    clear_output()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
